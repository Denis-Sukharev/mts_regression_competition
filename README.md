# Соревнование в рамках курса от МТС ШАД по задаче регрессии

![alt text](image.png)

## Описание задачи

**Основная цель:** 

Реализовать модель регрессии, которая предсказывает целевую переменную с точностью выше baseline метрики (*public MSE=10986.9*, *privat MSE=10543.3*).

**Метрика качества:** 

По условию соревнования в качестве метрики использовалась среднеквадратичная ошибка (MSE), оценивающая среднее отклонение предсказаний модели от реальных значений. Лидерборд соревнования Kaggle формировался на основе примерно 66% тестовых данных, а финальный результат — на оставшихся 34%.

## Структура проекта

Проект организован следующим образом для ясности и удобства использования:

```
mts_regression_competition/
├── README.md                  # данный файл
├── image.png                  # скриншот submission
├── teta-ml-2.ipynb            # файл с решением
│
└── data/                      # папка для данных
    ├── train.csv              # обучающие данные
    ├── test.csv               # тестовые данные
    ├── submission.csv         # предсказания
    └── sample_submission.csv  # пример файла для отправки
```

## Данные
*   **Источник:** данные предоставлены в рамках соревнования от МТС ШАД.
*   **Описание:**
    *   name: название объекта.
    *   _id: уникальный идентификатор.
    *   host_name: имя владельца или хоста, который предоставляет жилье.
    *   location_cluster: кластеризация местоположений (например, группировка объектов по районам или зонам).
    *   location: описание местоположения объекта.
    *   lat, lon: широта и долгота местоположения объекта.
    *   type_house: тип жилья.
    *   sum: общая стоимость аренды или сумма за определенный период.
    *   min_days: минимальное количество дней для бронирования объекта.
    *   amt_reviews: количество отзывов, оставленных для данного объекта.
    *   last_dt: дата последнего отзыва или последнего бронирования.
    *   avg_reviews: средний рейтинг или среднее количество отзывов за определенный период.
    *   total_host: общее количество объектов, принадлежащих одному хосту.
    *   target: целевая переменная.

## Feature Engineering
- Заполнены пропуски в столбцах 'name' и 'host_name' строкой 'NONE'.
- Столбец 'last_dt' преобразован в формат datetime:
    - Пропущенные даты 'last_dt' заполнены модой по 'type_house' и 'location_cluster'.
- Из 'last_dt'извелкаются признаки: 'year', 'month', 'day_of_month' и 'weekday'.
- Расчитано количества дней с момента последнего отзыва для каждого объекта – 'days_since_last'.
- Для каждого 'host_name' рассчитаны:
    - Средний рейтинг всех объектов – 'host_avg_rating'.
    - Cреднее количество отзывов всех объектов – 'host_avg_amt_reviews'.
    - Cредняя цена всех объектов – 'host_avg_sum'.
    - Количество объектов у хоста – 'host_obj_count'.
- Вычислены геопризнаки:
    - Расстояние между двумя точками (точка из набора данных и точка с координатами (0, 0)) по формуле гаверсинуса – 'hav_dist'.
    - Угол от двух точек (точка из набора данных и точка с координатами (0, 0)) относительно нулевого меридиана – 'bearing_degree'.
- Удалены неныжные признаки, использованные при генерации других признаков.
- Категориальные признаки передавались в модель напрямую.


## Модель
В качестве модели выбран *CatBoostRegressor* — градиентный бустинг на решающих деревьях, поскольку:
- Обработка категориальных признаков проводится без необходимости явного кодирования.
- CatBoost позволяет работать с NaN без дополнительных обработок.

В качестве loss-функции использовалась *RMSE* (корень из среднеквадратичной ошибки), поскольку из условия соревнования необходимо использовать метрику качества MSE, однако RMSE имеет имеет ту же размерность, что и целевая переменная, в отличие от MSE, у которой единицы в квадрате, что проще интерпретируется.


## Особенности при обучении модели
- *Гиперпараметры*: iterations, learning_rate, depth, random_state, verbose.
- *Loss-функция* – RMSE.
- *Кросс-валидация* – 5 фолдов с перемешиванием. Позволяет уменьшить риск переобучения и обеспечить устойчивую оценку модели.
- Автоматическое указание категориальных признаков через 'cat_features'.
- Подбор гиперпараметров и выбор лучшей модели проводился по минимальному значению MSE на валидационной выборке.
- Финальное дообучение на всей выборке.


## Валидация модели
- Для валидации использована K-Fold кросс-валидация с 5 фолдами и перемешиванием.
- Оценка качества модели проводилась на валидационных выборках по метрикам RMSE и MSE.
- Построен график остатков Q-Q plot.


## Результаты
**Baseline был успешно побит** (*public MSE=9684.9*, *privat MSE=9182.5*).
Тем не менее, есть возможности для дальнейшего улучшения результатов:
- Провести глубокий автоматический подбор гиперпараметров с расширенным пространством поиска для повышения точности предсказаний.
- Улучшить признаки и исключить неинформативные, что позволит повысить выразительность модели.
- Провести эксперементы с использованием других функций потерь для оптимизации модели.
- Сравнить другие модели и попробовать реализацию ансамблевых методов.

